{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95353eb8-7d8c-4072-bb4c-6f9d83fbd91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bdd1c8d-efc6-4e9b-b4ee-c0e4d840240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('job_descriptions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62baed9b-25b2-4713-a26c-ec93883dcc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Job Id', 'Experience', 'Qualifications', 'Salary Range', 'location',\n",
       "       'Country', 'latitude', 'longitude', 'Work Type', 'Company Size',\n",
       "       'Job Posting Date', 'Preference', 'Contact Person', 'Contact',\n",
       "       'Job Title', 'Role', 'Job Portal', 'Job Description', 'Benefits',\n",
       "       'skills', 'Responsibilities', 'Company', 'Company Profile'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27533bfd-554b-4c4a-a4bf-21e37fb93ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Company Profile'],inplace=True)\n",
    "df.drop(columns=['Contact'],inplace=True)\n",
    "df.drop(columns=['Contact Person'],inplace=True)\n",
    "df.drop(columns=['Job Id'],inplace=True)\n",
    "df.drop(columns=['Job Posting Date'],inplace=True)\n",
    "columns_to_drop = ['latitude', 'longitude', 'Job Portal']\n",
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "564e2acc-ae52-4b0d-bd88-462aaad31ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Min Salary', 'Max Salary']] = df['Salary Range'].str.extract(r'\\$?(\\d+)[kK]-\\$?(\\d+)[kK]')\n",
    "\n",
    "# Convert extracted values to numeric and multiply by 1000\n",
    "df['Min Salary'] = pd.to_numeric(df['Min Salary']) * 1000\n",
    "df['Max Salary'] = pd.to_numeric(df['Max Salary']) * 1000\n",
    "\n",
    "# Optionally, you can create an average salary column\n",
    "df['Average Salary'] = (df['Min Salary'] + df['Max Salary']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3da38aad-b88c-4812-9dcd-4262cbef163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# le = LabelEncoder()\n",
    "# col = ['Experience', 'Qualifications', 'location', 'Country',\n",
    "#        'Work Type', 'Company Size', 'Preference', 'Job Title', \n",
    "#        'Role', 'Benefits', \n",
    "#        'Responsibilities', 'Company']\n",
    "\n",
    "# encoding_dict={}\n",
    "\n",
    "# # Loop through each categorical column and apply LabelEncoder\n",
    "# for c in col:\n",
    "#     df[c] = le.fit_transform(df[c].astype(str))  \n",
    "#     encoding_dict[c] = {index: label for index, label in enumerate(le.classes_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b12bafad-0eae-44ee-87aa-06e8616c9edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Job Descriptions after Preprocessing:\n",
      "1615940\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Sample job descriptions\n",
    "job_descriptions = df['Job Description'].tolist()\n",
    "\n",
    "# Print original job descriptions\n",
    "# print(\"Original Job Descriptions:\")\n",
    "# print(job_descriptions)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Ensure that the input is a string\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Removing non-alphabetical characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Removing stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Debugging: Print tokens after removing stopwords\n",
    "    # print(f\"Tokens after stopword removal: {tokens}\")  # Debugging line\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    # Return the processed text\n",
    "    processed_text = ' '.join(tokens)\n",
    "\n",
    "    # Debugging: Print processed text for each job description\n",
    "    # print(f\"Processed text: '{processed_text}'\")  # Debugging line\n",
    "\n",
    "    return processed_text\n",
    "\n",
    "# Apply the preprocessing to the 'Job Description' column\n",
    "job_descriptions = df['Job Description'].apply(preprocess_text).tolist()\n",
    "\n",
    "# Filter out empty descriptions\n",
    "job_descriptions = [desc for desc in job_descriptions if desc]  # Keep only non-empty descriptions\n",
    "\n",
    "# Print the final job descriptions after preprocessing\n",
    "print(\"Final Job Descriptions after Preprocessing:\")\n",
    "print(len(job_descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c75dd294-3ee2-4035-9daa-c9bb92e55d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cde0a50-2c4c-4a93-9b1e-6214648802d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorise all job descriptions\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorized_data = vectorizer.fit_transform(job_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64f826d3-8efe-4633-8be6-566fd97daf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "front-end react developer\n",
      "most_similar_idx 301\n",
      "Best matched job: Front-End Engineer\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def match_job_description(user_input):\n",
    "    print(user_input)\n",
    "    # Preprocess the user input\n",
    "    user_input_processed = preprocess_text(user_input)\n",
    "    \n",
    "    # Vectorize the user input\n",
    "    user_vector = vectorizer.transform([user_input_processed])\n",
    "    # Compute cosine similarity with job descriptions\n",
    "    similarities = cosine_similarity(user_vector, vectorized_data)\n",
    "    \n",
    "    # Get the index of the most similar job description\n",
    "    most_similar_idx = similarities.argmax()\n",
    "    print(\"most_similar_idx\", most_similar_idx)\n",
    "    \n",
    "    # Return the corresponding job title\n",
    "    return df['Job Title'].iloc[most_similar_idx]\n",
    "\n",
    "# Example usage\n",
    "user_input = \"front-end react developer\"\n",
    "matched_job = match_job_description(user_input)\n",
    "\n",
    "print(f\"Best matched job: {matched_job}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe05afa0-acec-4620-8e5d-4b613055d9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n"
     ]
    }
   ],
   "source": [
    "skills = df['skills'].unique()\n",
    "print(len(skills))\n",
    "# Apply the preprocessing to the 'Job Description' column\n",
    "skills_processed = df['skills'].apply(preprocess_text).tolist()\n",
    "# skills_processed = [preprocess_text(skill) for skill in skills]\n",
    "\n",
    "# Filter out empty descriptions\n",
    "skills_processed = [desc for desc in skills_processed if desc]  # Keep only non-empty descriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e26474d-59cb-4f88-b25b-10f354bda63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1615940"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(skills_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc293107-01d4-427c-979d-5048be30d76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_skills = TfidfVectorizer()\n",
    "vectorized_data = vectorizer_skills.fit_transform(skills_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c6b0edc-0955-4e3a-b51f-a8f5b5fa4c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "web development\n",
      "most_similar_idx 29\n",
      "Best matched job: UI Developer\n",
      "Job title:  UI Developer\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def match_skills(user_input):\n",
    "    print(user_input)\n",
    "    # Preprocess the user input\n",
    "    user_input_processed = preprocess_text(user_input)\n",
    "    \n",
    "    # Vectorize the user input\n",
    "    user_vector = vectorizer_skills.transform([user_input_processed])\n",
    "    # Compute cosine similarity with job descriptions\n",
    "    similarities = cosine_similarity(user_vector, vectorized_data)\n",
    "    \n",
    "    # Get the index of the most similar job description\n",
    "    most_similar_idx = similarities.argmax()\n",
    "    print(\"most_similar_idx\", most_similar_idx)\n",
    "    # df.iloc[most_similar_idx],\n",
    "    # Return the corresponding job title\n",
    "    return df['Job Title'].iloc[most_similar_idx]\n",
    "\n",
    "# Example usage\n",
    "user_input = \"web development\"\n",
    "matched_job = match_skills(user_input)\n",
    "\n",
    "print(f\"Best matched job: {matched_job}\")\n",
    "print('Job title: ', matched_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394e3b4e-9437-4053-9342-e1443bbcf7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
